{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import norm\n",
    "from tqdm import tqdm\n",
    "\n",
    "from Chempy.parameter import ModelParameters\n",
    "\n",
    "import sbi.utils as utils\n",
    "\n",
    "import torch\n",
    "from torch.distributions.normal import Normal\n",
    "from torch.distributions.uniform import Uniform\n",
    "\n",
    "import time as t\n",
    "import pickle\n",
    "\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"NPE_C\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Load the data -----\n",
    "a = ModelParameters()\n",
    "labels = [a.to_optimize[i] for i in range(len(a.to_optimize))] + ['time']\n",
    "priors = torch.tensor([[a.priors[opt][0], a.priors[opt][1]] for opt in a.to_optimize])\n",
    "\n",
    "elements = a.elements_to_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (pytensor.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n",
      "/export/home/bguenes/envs/master_chempy_multi/lib/python3.12/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n"
     ]
    }
   ],
   "source": [
    "# ----- Load posterior -----\n",
    "with open(f'data/posterior_{name}.pickle', 'rb') as f:\n",
    "    posterior = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3888073/3901098474.py:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('data/pytorch_state_dict.pt'))\n"
     ]
    }
   ],
   "source": [
    "# ----- Load the NN -----\n",
    "class Model_Torch(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model_Torch, self).__init__()\n",
    "        self.l1 = torch.nn.Linear(len(labels), 100)\n",
    "        self.l2 = torch.nn.Linear(100, 40)\n",
    "        self.l3 = torch.nn.Linear(40, len(elements))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(self.l1(x))\n",
    "        x = torch.tanh(self.l2(x))\n",
    "        x = self.l3(x)\n",
    "        return x\n",
    "    \n",
    "model = Model_Torch()\n",
    "model.load_state_dict(torch.load('data/pytorch_state_dict.pt'))\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup priors\n",
    "The inputs to the model are drawn from a fixed set of global galaxy parameters (slope of the IMF & Rate of Type Ia Supernove) and a set of local star parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_GP = utils.MultipleIndependent(\n",
    "    [Normal(p[0]*torch.ones(1), p[1]*torch.ones(1)) for p in priors[2:]] +\n",
    "    [Uniform(torch.tensor([2.0]), torch.tensor([12.8]))],\n",
    "    validate_args=False)\n",
    "\n",
    "global_GP = utils.MultipleIndependent(\n",
    "    [Normal(p[0]*torch.ones(1), p[1]*torch.ones(1)) for p in priors[:2]],\n",
    "    validate_args=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate data\n",
    "With the set global priors and for each $N_{\\rm stars}$ a set of local priors, we can simulate the data with the Neural Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_stars = 1000\n",
    "\n",
    "stars = local_GP.sample((N_stars,))\n",
    "global_params = torch.tensor([[-2.3, -2.89]])\n",
    "\n",
    "stars = torch.cat((global_params.repeat(N_stars, 1), stars), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to create data for 1000 stars: 0.002 s\n"
     ]
    }
   ],
   "source": [
    "# ----- Simulate abundances -----\n",
    "start = t.time()\n",
    "abundances = model(stars)  \n",
    "# Remove H from data, because it is just used for normalization (output with index 2)\n",
    "abundances = torch.cat([abundances[:,0:2], abundances[:,3:]], axis=1)\n",
    "end = t.time()\n",
    "print(f'Time to create data for {N_stars} stars: {end-start:.3f} s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SBI with 5% observation error noise\n",
    "Need to load the posterior trained with a 5% observation error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(true_abundances):\n",
    "    # Define observational erorrs\n",
    "    pc_ab = 5 # percentage error in abundance\n",
    "\n",
    "    # Jitter true abundances and birth-times by these errors to create mock observational values.\n",
    "    obs_ab_errors = np.ones_like(true_abundances)*float(pc_ab)/100.\n",
    "    obs_abundances = norm.rvs(loc=true_abundances,scale=obs_ab_errors)\n",
    "\n",
    "    return obs_abundances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:05<00:00, 166.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to run 1000 simulations for 1000 stars: 6.004 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "thetas = []\n",
    "simulations = 1000\n",
    "\n",
    "start = t.time()\n",
    "for i in tqdm(range(len(abundances))):\n",
    "    x = add_noise(abundances[i].detach().numpy())\n",
    "    theta = posterior.sample((simulations,), x=x, show_progress_bars=False).T\n",
    "    thetas.append(theta)\n",
    "end = t.time()\n",
    "print(f'Time to run {simulations} simulations for {N_stars} stars: {end-start:.3f} s')\n",
    "\n",
    "thetas = np.array(thetas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log Prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetas_mean = thetas.mean(axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = torch.tensor(np.mgrid[-2.40:-2.25:0.001, -3.0:-2.85:0.001]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "grids = np.concatenate(\n",
    "    (x.reshape(-1, 1), y.reshape(-1, 1)),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:24<00:00, 41.46it/s]\n"
     ]
    }
   ],
   "source": [
    "log_prob = np.array([posterior.log_prob(np.concatenate((grids, np.tile(thetas_mean[i,2:],(grids.shape[0],1))), axis=1), x=abundances[i]) for i in tqdm(range(len(abundances)))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = log_prob.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = np.exp(p - p.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = stats.multivariate_normal.pdf(grids, mean=[-2.30, -2.89], cov=np.diag([0.3, 0.3])) * np.exp(p - p.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.3000,  0.3000],\n",
      "        [-2.8900,  0.3000],\n",
      "        [-0.3000,  0.3000],\n",
      "        [ 0.5500,  0.1000],\n",
      "        [ 0.5000,  0.1000]])\n"
     ]
    }
   ],
   "source": [
    "print(priors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.2938318, -2.8836331], dtype=float32)"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thetas_mean.mean(axis=0)[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-2.3630), tensor(-2.9520))"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a,b = np.unravel_index(prob.argmax(), x.shape)\n",
    "x[a,b], y[a,b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.contourf(x,y, prob.reshape(*x.shape));\n",
    "plt.scatter(thetas_mean.mean(axis=0)[0], thetas_mean.mean(axis=0)[1], c='r', s=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.3000,  0.3000],\n",
      "        [-2.8900,  0.3000],\n",
      "        [-0.3000,  0.3000],\n",
      "        [ 0.5500,  0.1000],\n",
      "        [ 0.5000,  0.1000]])\n"
     ]
    }
   ],
   "source": [
    "print(priors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size = 0.01\n",
    "l,m,n,o,p,q = torch.tensor(np.mgrid[-2.4:-2.2:step_size, -3.0:-2.8:step_size, -0.4:-0.2:step_size, 0.45:0.65:step_size, 0.4:0.6:step_size, 1:14:0.5]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "grids = np.concatenate(\n",
    "    (l.reshape(-1, 1), m.reshape(-1, 1), n.reshape(-1, 1), o.reshape(-1, 1), p.reshape(-1, 1), q.reshape(-1, 1)),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/1000 [00:57<3:09:27, 11.42s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[513], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m log_prob \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mposterior\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mabundances\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(abundances)))])\n",
      "File \u001b[0;32m~/envs/master_chempy_multi/lib/python3.12/site-packages/sbi/inference/posteriors/direct_posterior.py:232\u001b[0m, in \u001b[0;36mDirectPosterior.log_prob\u001b[0;34m(self, theta, x, norm_posterior, track_gradients, leakage_correction_params)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposterior_estimator\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(track_gradients):\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;66;03m# Evaluate on device, move back to cpu for comparison with prior.\u001b[39;00m\n\u001b[0;32m--> 232\u001b[0m     unnorm_log_prob \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mposterior_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_prob\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtheta_density_estimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcondition\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_density_estimator\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# `log_prob` supports only a single observation (i.e. `batchsize==1`).\u001b[39;00m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;66;03m# We now remove this additional dimension.\u001b[39;00m\n\u001b[1;32m    237\u001b[0m     unnorm_log_prob \u001b[38;5;241m=\u001b[39m unnorm_log_prob\u001b[38;5;241m.\u001b[39msqueeze(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/envs/master_chempy_multi/lib/python3.12/site-packages/sbi/neural_nets/estimators/nflows_flow.py:109\u001b[0m, in \u001b[0;36mNFlowsFlow.log_prob\u001b[0;34m(self, input, condition)\u001b[0m\n\u001b[1;32m    106\u001b[0m ones_for_event_dims \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m,) \u001b[38;5;241m*\u001b[39m condition_event_dims  \u001b[38;5;66;03m# Tuple of 1s, e.g. (1, 1, 1)\u001b[39;00m\n\u001b[1;32m    107\u001b[0m condition \u001b[38;5;241m=\u001b[39m condition\u001b[38;5;241m.\u001b[39mrepeat(input_sample_dim, \u001b[38;5;241m*\u001b[39mones_for_event_dims)\n\u001b[0;32m--> 109\u001b[0m log_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcondition\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m log_probs\u001b[38;5;241m.\u001b[39mreshape((input_sample_dim, input_batch_dim))\n",
      "File \u001b[0;32m~/envs/master_chempy_multi/lib/python3.12/site-packages/nflows/distributions/base.py:40\u001b[0m, in \u001b[0;36mDistribution.log_prob\u001b[0;34m(self, inputs, context)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m context\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m     37\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     38\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of input items must be equal to number of context items.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     39\u001b[0m         )\n\u001b[0;32m---> 40\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/envs/master_chempy_multi/lib/python3.12/site-packages/nflows/flows/base.py:39\u001b[0m, in \u001b[0;36mFlow._log_prob\u001b[0;34m(self, inputs, context)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_log_prob\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, context):\n\u001b[1;32m     38\u001b[0m     embedded_context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding_net(context)\n\u001b[0;32m---> 39\u001b[0m     noise, logabsdet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedded_context\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m     log_prob \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_distribution\u001b[38;5;241m.\u001b[39mlog_prob(noise, context\u001b[38;5;241m=\u001b[39membedded_context)\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m log_prob \u001b[38;5;241m+\u001b[39m logabsdet\n",
      "File \u001b[0;32m~/envs/master_chempy_multi/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/envs/master_chempy_multi/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/envs/master_chempy_multi/lib/python3.12/site-packages/nflows/transforms/base.py:56\u001b[0m, in \u001b[0;36mCompositeTransform.forward\u001b[0;34m(self, inputs, context)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     55\u001b[0m     funcs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transforms\n\u001b[0;32m---> 56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cascade\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfuncs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/envs/master_chempy_multi/lib/python3.12/site-packages/nflows/transforms/base.py:50\u001b[0m, in \u001b[0;36mCompositeTransform._cascade\u001b[0;34m(inputs, funcs, context)\u001b[0m\n\u001b[1;32m     48\u001b[0m total_logabsdet \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mnew_zeros(batch_size)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m funcs:\n\u001b[0;32m---> 50\u001b[0m     outputs, logabsdet \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     total_logabsdet \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m logabsdet\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs, total_logabsdet\n",
      "File \u001b[0;32m~/envs/master_chempy_multi/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/envs/master_chempy_multi/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/envs/master_chempy_multi/lib/python3.12/site-packages/nflows/transforms/autoregressive.py:39\u001b[0m, in \u001b[0;36mAutoregressiveTransform.forward\u001b[0;34m(self, inputs, context)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     38\u001b[0m     autoregressive_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautoregressive_net(inputs, context)\n\u001b[0;32m---> 39\u001b[0m     outputs, logabsdet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_elementwise_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mautoregressive_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs, logabsdet\n",
      "File \u001b[0;32m~/envs/master_chempy_multi/lib/python3.12/site-packages/nflows/transforms/autoregressive.py:103\u001b[0m, in \u001b[0;36mMaskedAffineAutoregressiveTransform._elementwise_forward\u001b[0;34m(self, inputs, autoregressive_params)\u001b[0m\n\u001b[1;32m    101\u001b[0m log_scale \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlog(scale)\n\u001b[1;32m    102\u001b[0m outputs \u001b[38;5;241m=\u001b[39m scale \u001b[38;5;241m*\u001b[39m inputs \u001b[38;5;241m+\u001b[39m shift\n\u001b[0;32m--> 103\u001b[0m logabsdet \u001b[38;5;241m=\u001b[39m \u001b[43mtorchutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum_except_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_scale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_batch_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs, logabsdet\n",
      "File \u001b[0;32m~/envs/master_chempy_multi/lib/python3.12/site-packages/nflows/utils/torchutils.py:19\u001b[0m, in \u001b[0;36msum_except_batch\u001b[0;34m(x, num_batch_dims)\u001b[0m\n\u001b[1;32m     15\u001b[0m     x_ \u001b[38;5;241m=\u001b[39m x_\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x_\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msum_except_batch\u001b[39m(x, num_batch_dims\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     20\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Sums all elements of `x` except for the first `num_batch_dims` dimensions.\"\"\"\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m check\u001b[38;5;241m.\u001b[39mis_nonnegative_int(num_batch_dims):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "log_prob = np.array([posterior.log_prob(grids, x=abundances[i]) for i in tqdm(range(len(abundances)))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_sum = log_prob.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = np.exp(prob_sum - prob_sum.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (1248,6) (2,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[482], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m prob \u001b[38;5;241m=\u001b[39m \u001b[43mstats\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultivariate_normal\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2.30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2.89\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcov\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiag\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mexp(p \u001b[38;5;241m-\u001b[39m p\u001b[38;5;241m.\u001b[39mmax())\n",
      "File \u001b[0;32m~/envs/master_chempy_multi/lib/python3.12/site-packages/scipy/stats/_multivariate.py:587\u001b[0m, in \u001b[0;36mmultivariate_normal_gen.pdf\u001b[0;34m(self, x, mean, cov, allow_singular)\u001b[0m\n\u001b[1;32m    585\u001b[0m dim, mean, cov_object \u001b[38;5;241m=\u001b[39m params\n\u001b[1;32m    586\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_quantiles(x, dim)\n\u001b[0;32m--> 587\u001b[0m out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_logpdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcov_object\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(cov_object\u001b[38;5;241m.\u001b[39mrank \u001b[38;5;241m<\u001b[39m dim):\n\u001b[1;32m    589\u001b[0m     out_of_bounds \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m~\u001b[39mcov_object\u001b[38;5;241m.\u001b[39m_support_mask(x\u001b[38;5;241m-\u001b[39mmean)\n",
      "File \u001b[0;32m~/envs/master_chempy_multi/lib/python3.12/site-packages/scipy/stats/_multivariate.py:530\u001b[0m, in \u001b[0;36mmultivariate_normal_gen._logpdf\u001b[0;34m(self, x, mean, cov_object)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Log of the multivariate normal probability density function.\u001b[39;00m\n\u001b[1;32m    512\u001b[0m \n\u001b[1;32m    513\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    527\u001b[0m \n\u001b[1;32m    528\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    529\u001b[0m log_det_cov, rank \u001b[38;5;241m=\u001b[39m cov_object\u001b[38;5;241m.\u001b[39mlog_pdet, cov_object\u001b[38;5;241m.\u001b[39mrank\n\u001b[0;32m--> 530\u001b[0m dev \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dev\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    532\u001b[0m     log_det_cov \u001b[38;5;241m=\u001b[39m log_det_cov[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, np\u001b[38;5;241m.\u001b[39mnewaxis]\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (1248,6) (2,) "
     ]
    }
   ],
   "source": [
    "prob = stats.multivariate_normal.pdf(grids, mean=[-2.30, -2.89], cov=np.diag([0.3, 0.3])) * np.exp(p - p.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.3000,  0.3000],\n",
      "        [-2.8900,  0.3000],\n",
      "        [-0.3000,  0.3000],\n",
      "        [ 0.5500,  0.1000],\n",
      "        [ 0.5000,  0.1000]])\n"
     ]
    }
   ],
   "source": [
    "print(priors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.2938318 , -2.8836331 , -0.31759816,  0.532531  ,  0.48236075,\n",
       "        7.1306887 ], dtype=float32)"
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thetas_mean.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-2.3000),\n",
       " tensor(-2.8000),\n",
       " tensor(-0.3000),\n",
       " tensor(0.5500),\n",
       " tensor(0.4000),\n",
       " tensor(4.5000))"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = np.unravel_index(prob.argmax(), l.shape)\n",
    "l[index], m[index], n[index], o[index], p[index]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_chempy_multi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
